{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_path = \"D:\\\\Machine Learning Datasets\\\\Tomato Plant Disease Classification Dataset - Kanchana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tomato_Bacterial_Spot',\n",
       " 'Tomato_Early_Blight',\n",
       " 'Tomato_Healthy',\n",
       " 'Tomato_Late_Blight',\n",
       " 'Tomato_Leaf_Mold',\n",
       " 'Tomato_Spider_Mite_Damage',\n",
       " 'Tomato_Target_Spot',\n",
       " 'Tomato_Yellow_Leaf_Curl_Virus']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(original_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomato_Bacterial_Spot : 2128\n",
      "Tomato_Early_Blight : 999\n",
      "Tomato_Healthy : 1000\n",
      "Tomato_Late_Blight : 917\n",
      "Tomato_Leaf_Mold : 951\n",
      "Tomato_Spider_Mite_Damage : 1568\n",
      "Tomato_Target_Spot : 1404\n",
      "Tomato_Yellow_Leaf_Curl_Virus : 2739\n"
     ]
    }
   ],
   "source": [
    "for fldr in os.listdir(original_dataset_path):\n",
    "    filenames = os.listdir(os.path.join(original_dataset_path,fldr))\n",
    "    print(\"%s : %d\"%(fldr,len(filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_path = \"D:\\\\Machine Learning Datasets\\\\Tomato Plant Disease Classification Dataset - Simplified\"\n",
    "mkdir(new_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save(fin, fout):\n",
    "    img = Image.open(fin, 'r')\n",
    "    out = img.resize((224, 224))\n",
    "    out.save(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_path = os.path.join(new_dataset_path,'resized')\n",
    "mkdir(resized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomato_Bacterial_Spot\n",
      "Tomato_Early_Blight\n",
      "Tomato_Healthy\n",
      "Tomato_Late_Blight\n",
      "Tomato_Leaf_Mold\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'D:\\\\Machine Learning Datasets\\\\Tomato Plant Disease Classification Dataset - Kanchana\\\\Tomato_Leaf_Mold\\\\Crnl_L.Mold 8643.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ff77b199d737>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_dataset_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfname1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfname1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mresize_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-89e0e2b2fd75>\u001b[0m in \u001b[0;36mresize_and_save\u001b[1;34m(fin, fout)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mresize_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\python37_cv\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2929\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2930\u001b[0m     raise UnidentifiedImageError(\n\u001b[1;32m-> 2931\u001b[1;33m         \u001b[1;34m\"cannot identify image file %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2932\u001b[0m     )\n\u001b[0;32m   2933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'D:\\\\Machine Learning Datasets\\\\Tomato Plant Disease Classification Dataset - Kanchana\\\\Tomato_Leaf_Mold\\\\Crnl_L.Mold 8643.JPG'"
     ]
    }
   ],
   "source": [
    "for class_label in os.listdir(original_dataset_path):\n",
    "    print(class_label)\n",
    "    mkdir(os.path.join(resized_path,class_label))\n",
    "\n",
    "    filenames = os.listdir(os.path.join(original_dataset_path,class_label))\n",
    "    \n",
    "    for fname1 in filenames:\n",
    "        f1=os.path.join(original_dataset_path,class_label,fname1)\n",
    "        f2=os.path.join(resized_path,class_label,fname1)\n",
    "        resize_and_save(f1,f2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tomato_Leaf_Mold',\n",
       " 'Tomato_Spider_Mite_Damage',\n",
       " 'Tomato_Target_Spot',\n",
       " 'Tomato_Yellow_Leaf_Curl_Virus']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(original_dataset_path)[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomato_Leaf_Mold\n",
      "Tomato_Spider_Mite_Damage\n",
      "Tomato_Target_Spot\n",
      "Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "for class_label in os.listdir(original_dataset_path)[4:]:\n",
    "    print(class_label)\n",
    "    mkdir(os.path.join(resized_path,class_label))\n",
    "\n",
    "    filenames = os.listdir(os.path.join(original_dataset_path,class_label))\n",
    "    \n",
    "    for fname1 in filenames:\n",
    "        f1=os.path.join(original_dataset_path,class_label,fname1)\n",
    "        f2=os.path.join(resized_path,class_label,fname1)\n",
    "        try:\n",
    "            resize_and_save(f1,f2)\n",
    "        except UnidentifiedImageError as e:\n",
    "            print('UnidentifiedImageError',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test Split [90%-5%-5%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_path = os.path.join(new_dataset_path,'train')\n",
    "valset_path = os.path.join(new_dataset_path,'val')\n",
    "testset_path = os.path.join(new_dataset_path,'test')\n",
    "\n",
    "mkdir(trainset_path)\n",
    "mkdir(valset_path)\n",
    "mkdir(testset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomato_Bacterial_Spot\n",
      "Total: 2128,  Train: 1915,  Validation: 106,  Test: 107 \n",
      "\n",
      "Tomato_Early_Blight\n",
      "Total: 999,  Train: 899,  Validation: 50,  Test: 50 \n",
      "\n",
      "Tomato_Healthy\n",
      "Total: 1000,  Train: 900,  Validation: 50,  Test: 50 \n",
      "\n",
      "Tomato_Late_Blight\n",
      "Total: 917,  Train: 825,  Validation: 46,  Test: 46 \n",
      "\n",
      "Tomato_Leaf_Mold\n",
      "Total: 821,  Train: 738,  Validation: 41,  Test: 42 \n",
      "\n",
      "Tomato_Spider_Mite_Damage\n",
      "Total: 1568,  Train: 1411,  Validation: 78,  Test: 79 \n",
      "\n",
      "Tomato_Target_Spot\n",
      "Total: 1404,  Train: 1263,  Validation: 70,  Test: 71 \n",
      "\n",
      "Tomato_Yellow_Leaf_Curl_Virus\n",
      "Total: 2739,  Train: 2465,  Validation: 137,  Test: 137 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for class_label in os.listdir(resized_path):\n",
    "    print(class_label)\n",
    "    \n",
    "    mkdir(os.path.join(trainset_path,class_label))\n",
    "    mkdir(os.path.join(valset_path,class_label))\n",
    "    mkdir(os.path.join(testset_path,class_label))\n",
    "\n",
    "    filenames = os.listdir(os.path.join(resized_path,class_label))\n",
    "    random.shuffle(filenames)\n",
    "    \n",
    "    N=len(filenames)\n",
    "    idx1 = int(N*0.9)\n",
    "    idx2 = int(N*0.95)\n",
    "    \n",
    "    train_filenames=filenames[:idx1]\n",
    "    val_filenames=filenames[idx1:idx2]\n",
    "    test_filenames=filenames[idx2:]\n",
    "    \n",
    "    print(\"Total: %d,  Train: %d,  Validation: %d,  Test: %d \\n\"%(N,len(train_filenames),len(val_filenames),len(test_filenames)))\n",
    "    \n",
    "    #Train set\n",
    "    for fname1 in train_filenames:\n",
    "        f1=os.path.join(resized_path,class_label,fname1)\n",
    "        f2=os.path.join(trainset_path,class_label,fname1)\n",
    "        copyfile(f1,f2)\n",
    "    \n",
    "    #Validation set\n",
    "    for fname1 in val_filenames:\n",
    "        f1=os.path.join(resized_path,class_label,fname1)\n",
    "        f2=os.path.join(valset_path,class_label,fname1)\n",
    "        copyfile(f1,f2)\n",
    "        \n",
    "    #Test set\n",
    "    for fname1 in test_filenames:\n",
    "        f1=os.path.join(resized_path,class_label,fname1)\n",
    "        f2=os.path.join(testset_path,class_label,fname1)\n",
    "        copyfile(f1,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
